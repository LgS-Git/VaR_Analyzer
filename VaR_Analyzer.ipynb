{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc8cc73e",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c9a3da",
   "metadata": {},
   "source": [
    "The VaR_Analyzer takes in Ex-Post Data (Damage Case Database) and Ex-Ante Data (Workshop Results).  \n",
    "It aids in the statistical analysis of said data and arrives at a final result with a VaR simulation for operational risks.  \n",
    "After running the Import block, each block in the file can be run separately.\n",
    "\n",
    "Ex-Post Data resembles a Damage Case Database and should contain the amount of damage done, as well as a Time Stamp.\n",
    "\n",
    "Ex_Ante Data resembles results worked out with insiders in the firm to asses potential future damages. For each future scenario, the data should contain the expected yearly frequency of the event, the typical damage caused by the event (most likely amount of damage to occur), and the extreme damage (potential damage relating to the 99%-Quantile)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d17703",
   "metadata": {},
   "source": [
    "# Data Import\n",
    "\n",
    "Import own data or use/generate example data.\n",
    "\n",
    "Ex-Post Data should be structured with the headings:  \n",
    "'Event Name' ; 'Time Stamp' ; 'Loss'\n",
    "\n",
    "Ex-Ante Data should be structured with the headings:  \n",
    "'Scenario' ; 'Yearly Frequency' ; 'Typical Damage' ; 'Extreme Damage'\n",
    "\n",
    "For further reference see the structure of ._example_data in \\data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdfa78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.exploratory_analysis\n",
    "import src.distribution_estimation\n",
    "import src.generate_test_data\n",
    "import src.var_analysis\n",
    "import src.jupyter_notebook_functions\n",
    "from IPython.display import display, Markdown\n",
    "import pandas as pd\n",
    "\n",
    "# Import own data here or use example data\n",
    "exPost_filePath = 'data/exPost_example_data.xlsx'\n",
    "exAnte_filePath = 'data/exAnte_example_data.xlsx'\n",
    "\n",
    "# Uncomment to generate new example data\n",
    "#%run src\\generate_test_data.py\n",
    "\n",
    "exPost_df = pd.read_excel(exPost_filePath)\n",
    "exPost_df['Time Stamp'] = pd.to_datetime(exPost_df['Time Stamp'])\n",
    "exAnte_df = pd.read_excel(exAnte_filePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3b3065",
   "metadata": {},
   "source": [
    "# Exploratory Analysis (Ex-Post)\n",
    "\n",
    "This section provides an initial analyis of the Ex-Post Database, which can later aid in the estimation of the underlying distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f44189",
   "metadata": {},
   "source": [
    "### Losses per Year (Discrete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a8da37",
   "metadata": {},
   "outputs": [],
   "source": [
    "src.exploratory_analysis.exploratory_statistics_discrete(exPost_df['Time Stamp'].dt.year.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb27265c",
   "metadata": {},
   "source": [
    "### Loss severity per Loss (Continuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de5f168",
   "metadata": {},
   "outputs": [],
   "source": [
    "src.exploratory_analysis.exploratory_statistics_continuous(exPost_df['Loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc85262d",
   "metadata": {},
   "source": [
    "# Distribution Estimation\n",
    "\n",
    "This section provides assistance in finding the best fitting underlying distribution for the Data. Both the discrete distribution of losses per year, and a continous distribution resembling the severity of each loss can be fitted.\n",
    "\n",
    "For Ex-Post Data, the tool provides a dropdown menue, where several theoretical distributions can be fitted to each of the underlying distributions. It outputs the results of several statistical tests and displays a Quantile-to-Quantile plot, in order to visually assess the goodness of fit.\n",
    "The best fitting parametrization is automatically selected and displayed for each theoretical distribution.\n",
    "\n",
    "Since Ex-Ante Data is constructed from workshop results, each scenario is plotted with individual lognormal and poisson distributions and just the parameters are displayed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66d3ad6",
   "metadata": {},
   "source": [
    "## Ex-Post"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96563006",
   "metadata": {},
   "source": [
    "### Losses per Year (Discrete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da396fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropdown_discrete = src.jupyter_notebook_functions.create_discrete_dropdown()\n",
    "display(dropdown_discrete)\n",
    "\n",
    "dropdown_discrete.observe(lambda change: src.jupyter_notebook_functions.on_dropdown_discrete_change(change, exPost_df['Time Stamp'].dt.year.value_counts()), names='value')\n",
    "src.jupyter_notebook_functions.on_dropdown_discrete_change({'type': 'change', 'name': 'value', 'new': dropdown_discrete.value}, exPost_df['Time Stamp'].dt.year.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10a6f7f",
   "metadata": {},
   "source": [
    "### Loss severity per Loss (Continuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ed243c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropdown_continuous = src.jupyter_notebook_functions.create_continuous_dropdown()\n",
    "display(dropdown_continuous)\n",
    "\n",
    "dropdown_continuous.observe(lambda change: src.jupyter_notebook_functions.on_dropdown_continuous_change(change, exPost_df['Loss']), names='value')\n",
    "src.jupyter_notebook_functions.on_dropdown_continuous_change({'type': 'change', 'name': 'value', 'new': dropdown_continuous.value}, exPost_df['Loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7342878a",
   "metadata": {},
   "source": [
    "## Ex-Ante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40bcca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "src.distribution_estimation.exAnte_logNormalDistribution_parameters(exAnte_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d06b9dc",
   "metadata": {},
   "source": [
    "# VaR - Simulation\n",
    "\n",
    "This section simulates and displays yearly damages and calculates the VaR for both Ex-Post and Ex-Ante Data.\n",
    "\n",
    "The Ex-Post simulation requires a theroetical discrete and continuous distribution as input. To find the correct distributions, utilize the sections above.  \n",
    "For display reasons, the distribution names have to be provided manually.\n",
    "\n",
    "The simulation results for both Ex-Post and Ex-Ante Data are saved to .xlsx and can be found in the directory data/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196d876d",
   "metadata": {},
   "source": [
    "## Ex-Post\n",
    "\n",
    "Discrete Distributions: 'Poisson', 'Geometric', 'Negative Binomial'\n",
    "\n",
    "Continuous Distributions: 'Lognormal', 'Normal', 'Exponential', 'Gamma', 'Loggamma', 'Beta', 'Logistic', 'Gumbel_r', 'Gumbel_l', 'Weibull', 'Pareto', 'Cauchy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2801b391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of simulation steps n | Distribution for Losses per Year (Discrete) | Distribution for Severity of Loss (Continuous)\n",
    "n = 5000\n",
    "discrete_dist = 'Poisson'\n",
    "continuous_dist = 'Lognormal'\n",
    "\n",
    "src.var_analysis.perform_exPost_simulations(exPost_df, discrete_dist, continuous_dist, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fff9a78",
   "metadata": {},
   "source": [
    "## Ex-Ante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee81fe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of simulation steps\n",
    "n = 5000\n",
    "\n",
    "src.var_analysis.perform_exAnte_simulations(exAnte_df, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f72261",
   "metadata": {},
   "source": [
    "# VaR - Result\n",
    "\n",
    "This section combines both simulation results and calculates the total VaR given the weight of the exAnte simulation relative to the exPost simulation.\n",
    "\n",
    "CAREFUL: While this section can be run independently, it relies on the simulation results from the previous section, which are stored in data/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d871f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight of Ex-Ante Estimation compared to Ex-Post\n",
    "w_exAnte = 0.5\n",
    "\n",
    "VaR = src.var_analysis.combine_simulation_results('data/exAnte_simulation_results.xlsx', 'data/exPost_simulation_results.xlsx', w_exAnte)\n",
    "display(Markdown(f'## Total Value at Risk (99.9%): **{VaR}**'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
